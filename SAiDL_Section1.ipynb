{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Standard Softmax"
      ],
      "metadata": {
        "id": "fAcXo2bVrVZJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "0WGRzRrAq0bi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "9ReOtFZzqtBL"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "1OP4OALgq3kA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzhqOdExqipv",
        "outputId": "0da450d3-e068-4098-f9c7-d8baa29f2383"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169001437/169001437 [==============================] - 4s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Load the CIFAR100 dataset\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_train = keras.utils.to_categorical(y_train, 100)\n",
        "y_test = keras.utils.to_categorical(y_test, 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "_vw8OAhDq706"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model architecture\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\", input_shape=(32, 32, 3)),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\"),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\"),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(256, activation=\"relu\"),\n",
        "        layers.Dense(100, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, batch_size=64, epochs=10, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6C8FX_QPqypg",
        "outputId": "c6f6258e-af7f-40d3-a856-598231faa6da"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "782/782 [==============================] - 144s 178ms/step - loss: 3.7353 - accuracy: 0.1350 - val_loss: 3.1932 - val_accuracy: 0.2280\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 134s 171ms/step - loss: 2.9103 - accuracy: 0.2793 - val_loss: 2.7204 - val_accuracy: 0.3233\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 137s 176ms/step - loss: 2.5231 - accuracy: 0.3590 - val_loss: 2.5277 - val_accuracy: 0.3539\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 135s 172ms/step - loss: 2.2481 - accuracy: 0.4162 - val_loss: 2.4319 - val_accuracy: 0.3833\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 133s 170ms/step - loss: 2.0225 - accuracy: 0.4663 - val_loss: 2.3233 - val_accuracy: 0.4087\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 129s 165ms/step - loss: 1.8245 - accuracy: 0.5084 - val_loss: 2.4229 - val_accuracy: 0.4000\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 133s 170ms/step - loss: 1.6435 - accuracy: 0.5512 - val_loss: 2.3812 - val_accuracy: 0.4186\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 129s 165ms/step - loss: 1.4725 - accuracy: 0.5921 - val_loss: 2.4191 - val_accuracy: 0.4205\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 129s 165ms/step - loss: 1.3063 - accuracy: 0.6320 - val_loss: 2.5040 - val_accuracy: 0.4220\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 130s 167ms/step - loss: 1.1504 - accuracy: 0.6699 - val_loss: 2.5935 - val_accuracy: 0.4152\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7632c4fcd0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation of Model"
      ],
      "metadata": {
        "id": "q2xrw5p5rZG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Convert one-hot encoding back to labels\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Compute evaluation metrics\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred, average='macro')\n",
        "recall = recall_score(y_true, y_pred, average='macro')\n",
        "f1 = f1_score(y_true, y_pred, average='macro')\n",
        "confusion = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"Confusion Matrix:\\n\", confusion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmmvIqhJrYOs",
        "outputId": "75ce3a72-7751-4fa5-ef3c-7b04a4332b5c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 8s 26ms/step\n",
            "Accuracy: 0.4152\n",
            "Precision: 0.4342838332714296\n",
            "Recall: 0.41519999999999996\n",
            "F1 Score: 0.41567851811053136\n",
            "Confusion Matrix:\n",
            " [[71  0  0 ...  0  0  0]\n",
            " [ 1 49  0 ...  0  0  0]\n",
            " [ 1  2 25 ...  1  9  2]\n",
            " ...\n",
            " [ 0  0  0 ... 33  0  0]\n",
            " [ 1  0  4 ...  1 25  1]\n",
            " [ 0  0  0 ...  0  2 47]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Different Softmax"
      ],
      "metadata": {
        "id": "1z3ra1ybsBWj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gumbel-Softmax"
      ],
      "metadata": {
        "id": "fk-HBInjsN8j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Gumbel-Softmax function\n",
        "def gumbel_softmax(logits, temperature):\n",
        "    # Sample from a Gumbel distribution\n",
        "    u = tf.random.uniform(tf.shape(logits), minval=0, maxval=1)\n",
        "    gumbel = -tf.math.log(-tf.math.log(u + 1e-20) + 1e-20)\n",
        "    \n",
        "    # Add the Gumbel noise to the logits and apply temperature\n",
        "    y = logits + gumbel\n",
        "    y = y / temperature\n",
        "    \n",
        "    # Compute the softmax\n",
        "    y = tf.nn.softmax(y)\n",
        "    \n",
        "    return y\n",
        "\n",
        "\n",
        "# Define the custom loss function using the Gumbel-Softmax function\n",
        "def gumbel_softmax_loss(y_true, y_pred):\n",
        "    y_pred = gumbel_softmax(y_pred, temperature)\n",
        "    loss = keras.losses.categorical_crossentropy(y_true, y_pred)\n",
        "    return loss"
      ],
      "metadata": {
        "id": "TGq1vwKxsP4Z"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "SQzhHclysQwl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CIFAR100 dataset\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_train = keras.utils.to_categorical(y_train, 100)\n",
        "y_test = keras.utils.to_categorical(y_test, 100)"
      ],
      "metadata": {
        "id": "zDBtdqtysUJq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "rqm5yNwusXV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model architecture\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\", input_shape=(32, 32, 3)),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\"),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\"),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(256, activation=\"relu\"),\n",
        "        layers.Dense(100, activation=None),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Define the temperature for the Gumbel-Softmax function\n",
        "temperature = 0.5\n",
        "# Compile the model with the custom loss function\n",
        "model.compile(optimizer=\"adam\", loss=gumbel_softmax_loss, metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, batch_size=64, epochs=10, validation_data=(x_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nk3iZJd1sV9X",
        "outputId": "4e5e0087-7554-4006-9e39-faab02e4c270"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "782/782 [==============================] - 138s 174ms/step - loss: 8.1812 - accuracy: 0.1134 - val_loss: 7.3058 - val_accuracy: 0.1862\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 141s 180ms/step - loss: 6.6097 - accuracy: 0.2415 - val_loss: 6.2432 - val_accuracy: 0.2715\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 130s 166ms/step - loss: 5.8226 - accuracy: 0.3176 - val_loss: 5.8222 - val_accuracy: 0.3307\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 129s 165ms/step - loss: 5.2898 - accuracy: 0.3677 - val_loss: 5.4696 - val_accuracy: 0.3536\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 134s 171ms/step - loss: 4.8556 - accuracy: 0.4093 - val_loss: 5.3970 - val_accuracy: 0.3689\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 133s 170ms/step - loss: 4.5082 - accuracy: 0.4474 - val_loss: 5.1709 - val_accuracy: 0.3908\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 133s 170ms/step - loss: 4.2134 - accuracy: 0.4816 - val_loss: 5.0980 - val_accuracy: 0.4075\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 134s 172ms/step - loss: 3.8780 - accuracy: 0.5108 - val_loss: 5.1593 - val_accuracy: 0.4006\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 135s 172ms/step - loss: 3.6298 - accuracy: 0.5437 - val_loss: 5.0969 - val_accuracy: 0.4169\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 136s 174ms/step - loss: 3.3675 - accuracy: 0.5715 - val_loss: 5.2798 - val_accuracy: 0.4152\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f75f28c78e0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation of Model"
      ],
      "metadata": {
        "id": "loL1Sq3ssgog"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Compute the evaluation metrics\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred, average=\"macro\")\n",
        "recall = recall_score(y_true, y_pred, average=\"macro\")\n",
        "f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"F1 score: {:.4f}\".format(f1))\n",
        "print(\"Confusion matrix:\")\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-OwyQLKswbm",
        "outputId": "1f567b91-f5f9-46c4-ae45-100445b39ad1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 7s 22ms/step\n",
            "Accuracy: 0.4152\n",
            "Precision: 0.4465\n",
            "Recall: 0.4152\n",
            "F1 score: 0.4164\n",
            "Confusion matrix:\n",
            "[[57  1  0 ...  0  0  0]\n",
            " [ 0 45  0 ...  0  0  2]\n",
            " [ 0  0 13 ...  2 14  0]\n",
            " ...\n",
            " [ 0  0  1 ... 49  1  0]\n",
            " [ 0  0  4 ...  1 32  0]\n",
            " [ 0  0  0 ...  0  0 46]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bonus"
      ],
      "metadata": {
        "id": "_TkSKBg7tDWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Define the input shape\n",
        "input_shape = (32, 32, 3)\n",
        "\n",
        "# Define the number of classes\n",
        "num_classes = 100\n",
        "\n",
        "# Define the number of attention heads\n",
        "num_heads = 8\n",
        "\n",
        "# Define the transformer layer\n",
        "def transformer_layer(inputs, hidden_size, num_heads):\n",
        "    # Multi-Head Attention\n",
        "    attn_output = layers.MultiHeadAttention(num_heads=num_heads, key_dim=hidden_size // num_heads)(inputs, inputs)\n",
        "    attn_output = layers.Dropout(0.1)(attn_output)\n",
        "    attn_output = layers.LayerNormalization(epsilon=1e-6)(inputs + attn_output)\n",
        "\n",
        "    # Feed Forward network\n",
        "    ffn = tf.keras.Sequential([\n",
        "        layers.Dense(hidden_size, activation='relu'),\n",
        "        layers.Dense(hidden_size)\n",
        "    ])\n",
        "    ffn_output = ffn(attn_output)\n",
        "    ffn_output = layers.Dropout(0.1)(ffn_output)\n",
        "    ffn_output = layers.LayerNormalization(epsilon=1e-6)(attn_output + ffn_output)\n",
        "\n",
        "    return ffn_output\n",
        "\n",
        "# Define the transformer-based model\n",
        "def transformer_model(num_classes, num_heads, hidden_size):\n",
        "    # Define the inputs\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Preprocessing layers\n",
        "    x = layers.experimental.preprocessing.Rescaling(1./255)(inputs)\n",
        "    x = layers.experimental.preprocessing.RandomCrop(30, 30)(x)\n",
        "\n",
        "    # Convolutional layers\n",
        "    x = layers.Conv2D(32, 3, activation='relu')(x)\n",
        "    x = layers.Conv2D(64, 3, activation='relu')(x)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "    x = layers.Dropout(0.25)(x)\n",
        "    x = layers.Flatten()(x)\n",
        "\n",
        "    # Transformer layers\n",
        "    x = layers.Dense(hidden_size)(x)\n",
        "    x = layers.Reshape((1, hidden_size))(x)\n",
        "    x = transformer_layer(x, hidden_size, num_heads)\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "\n",
        "    # Output layer with different softmax functions\n",
        "    outputs_softmax = layers.Dense(num_classes, activation='softmax')(x)\n",
        "    outputs_gumbel_softmax = layers.Dense(num_classes, activation='linear')(x)\n",
        "    outputs_gumbel_softmax = tf.nn.softmax(tf.random.gumbel(tf.shape(outputs_gumbel_softmax)) + outputs_gumbel_softmax)\n",
        "\n",
        "    # Define the model\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=[outputs_softmax, outputs_gumbel_softmax])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create an instance of the transformer-based model\n",
        "model = transformer_model(num_classes=num_classes, num_heads=num_heads, hidden_size=128)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=['categorical_crossentropy', 'categorical_crossentropy'], \n",
        "              optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, [y_train, y_train], \n",
        "                    batch_size=128, epochs=10, validation_data=(x_test, [y_test, y_test]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "JQcXL0yLtFQk",
        "outputId": "ee5221a6-c878-48bc-c285-62bb06dcb4dd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-4b86f6f7303d>\u001b[0m in \u001b[0;36m<cell line: 64>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;31m# Create an instance of the transformer-based model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;31m# Compile the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-4b86f6f7303d>\u001b[0m in \u001b[0;36mtransformer_model\u001b[0;34m(num_classes, num_heads, hidden_size)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0moutputs_softmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0moutputs_gumbel_softmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0moutputs_gumbel_softmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgumbel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs_gumbel_softmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutputs_gumbel_softmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# Define the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow._api.v2.random' has no attribute 'gumbel'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0lzJ2jAT6fE-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}